{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf601b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import csv  \n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91732916",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "#print(base_dir)\n",
    "city= \"ams\"\n",
    "#path to ancillary data folder\n",
    "ancillary_data_folder_path = base_dir + \"/data_prep/{}_Projectdata/AncillaryData\".format(city)\n",
    "ancillary_POPdata_folder_path = base_dir + \"/data_prep/{}_Projectdata/PopData\".format(city)\n",
    "data_folder =  base_dir + \"/model/pytorch_model/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0a0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## ## ## ## ----- CREATE NEW FOLDER  ----- ## ## ## ## ##\n",
    "def createFolder(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"------------------------------ Creating Folder : {} ------------------------------\".format(path))\n",
    "        os.makedirs(path)\n",
    "    else: \n",
    "        print(\"------------------------------ Folder already exists------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce75fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Folder already exists------------------------------\n"
     ]
    }
   ],
   "source": [
    "img_dir = base_dir + \"/model/pytorch_model/img_dir\"\n",
    "createFolder(img_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "\n",
    "for folder in os.listdir(data_folder):\n",
    "    classes.append(folder)\n",
    "    annotation = len(classes) - 1\n",
    "    #print(len(classes))\n",
    "    for file in os.listdir(data_folder+ \"/\" + folder):\n",
    "        if file.endswith(\".tif\"):\n",
    "            year = file.split(\".\")[0]\n",
    "            #print(file)\n",
    "            src = data_folder+ \"/\" + folder + \"/\" + file\n",
    "            dst = img_dir + \"/{0}_{1}.tif\".format(folder,year) \n",
    "            #copyfile(src, dst)\n",
    "            #row_data = []\n",
    "            \n",
    "            with open('labels.csv', mode='a', encoding='UTF8') as f:\n",
    "                f.write(\"{0}_{1}.tif, {2}\".format(folder,year, annotation))\n",
    "                f.write(\"\\n\")  # Next line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088f88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.folder import IMG_EXTENSIONS\n",
    "\n",
    "#len(ImageFolder(img_dir))  # prints 1\n",
    "\n",
    "IMG_EXTENSIONS.append('tif')\n",
    "\n",
    "len(ImageFolder(img_dir))  # prints 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95a8101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = 'labels.csv'\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        src = rasterio.open(img_path)\n",
    "        array = src.read(1)\n",
    "        image = ToTensor()(array)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13a1e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(annotations_file, img_dir)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = CustomImageDataset(annotations_file, img_dir)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c415aa3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1592/3324540842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display image and label.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Feature batch shape: {train_features.size()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Labels batch shape: {train_labels.size()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e19e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
